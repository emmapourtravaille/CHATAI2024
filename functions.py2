def quest_tokenize(question):
    """Tokenize the words of the question into individual words, remove punctuation and capital letter.
    Takes in parameter the question and returns a list."""
    question = question.replace("’", " ").replace("'", " ").replace(",", "").replace("-", " ").replace("!", "").replace(
        ":", "").replace(".", "").replace('"', "").replace("  ", " ")
    question = '\n'.join(line.strip() for line in question.split('\n') if line.strip())

    result_question = ''
    res = []

    for letter in question:
        if 65 <= ord(letter) <= 90 and letter != ' ':
            result_question += chr(ord(letter) + 32)
        elif letter == "É":
            result_question += "é"
        else:
            result_question += letter

    for words in result_question.split():
        res.append(words)
    return res


def search_for_words(directory, question):
    """Takes in parameter the directory and the question.
    This function returns a dictionary with the occurrence of the words in key"""
    question_set = set(quest_tokenize(question))
    dic_words = {}
    i = 1
    for file_name in list_of_files(directory, 'txt'):
        with open(os.path.join(directory, file_name), 'r', encoding='utf-8') as f:
            file = f.read().split()
            dic_words[i] = list(question_set.intersection(set(file)))
            i += 1
    return dic_words


def td_idf_matrix_question(directory, question):
    """Takes in parameter the directory and the question.
    Returns the td-idf matrix of the question."""
    clean_question_str = ''
    matrix_question = []
    clean_question = quest_tokenize(question)

    for words in clean_question:
        clean_question_str += words+" "
    tf_score = calculate_tf(clean_question_str)
    idf_score = calculate_idf(directory)

    for value in tf_score.values():
        value /= len(clean_question)
    for word in idf_score.keys():
        if word in tf_score:
            matrix_question.append(round(tf_score[word] * idf_score[word], 2))
        else:
            matrix_question.append(0)
    return matrix_question


def scalar_product(a, b):
    """Takes in parameter 2 vectors and returns the sum of Ai.Bi """
    the_sum = 0
    for i in range(len(a) - 1):
        the_sum += a[i] * b[i]
    return the_sum


def norm_vector(a):
    """Takes in parameter one vector and returns the sum of sqrt(Ai^2)"""
    return sqrt(sum(x ** 2 for x in a))


def calculate_similarity(a, b):
    """Compute the similiraties of theses vectors"""
    dot_product_result = dot_product(a, b)
    norm_a = norm_vector(a)
    norm_b = norm_vector(b)
   
    if norm_a * norm_b == 0:
        return 0
    similarity = dot_product_result / (norm_a * norm_b)
    return round(similarity, 2)


def find_most_relevant_document(tf_idf_matrix, question_tf_idf_vector, file_names):
    """Find the most relevant document given TF-IDF matrix, question TF-IDF vector, and file names"""
    similarities = [calculate_similarity(question_tf_idf_vector, doc_vector) for doc_vector in tf_idf_matrix]
    max_similarity_index = np.argmax(similarities)
    most_relevant_document_name = file_names[max_similarity_index]

    return most_relevant_document_name


def generate_response(question_tf_idf_vector, relevant_document, file_content):
    """Generate a response based on the TF-IDF vector of the question and the relevant document."""
    highest_tf_idf_index = question_tf_idf_vector.argmax()
    relevant_word = relevant_document.split('_')[1].split('.')[0]

    word_index = file_content.find(relevant_word)
    start_index = file_content.rfind('"', 0, word_index) + 1
    end_index = file_content.find('"', word_index)
    response = file_content[start_index:end_index].strip()

    return response



def generate_response_improved(question_tf_idf_vector, file_content):
    """Generate an improved response with proper formatting based on the TF-IDF vector of the question and the relevant document"""
    highest_tf_idf_index = question_tf_idf_vector.argmax()
    relevant_word = relevant_document.split('_')[1].split('.')[0]  

    word_index = file_content.find(relevant_word)
    start_index = file_content.rfind('"', 0, word_index) + 1
    end_index = file_content.find('"', word_index)
    response = file_content[start_index:end_index].strip()

    response = response[0].capitalize() + response[1:] + '.'

    return response

def generate_response_improved_2(question):  #Test of another way to do it
    """Generate an improved response with proper formatting based on the TF-IDF vector of the
    question and the relevant document"""
    maxi = 0
    question_matrix = td_idf_matrix_question("./cleaned", "question")
    non_zero_matrix = []
    max_score_word_question = ""
    for values in question_matrix:  # Find the index of the original words in the questions
        if values != 0:
            non_zero_matrix.append(values)

    if non_zero_matrix:
        maxi = max(non_zero_matrix)
        for words in question.split():
            if words in calculate_idf("./cleaned"):
                if maxi == (calculate_idf("./cleaned")[words]*calculate_tf(question)[words]):
                    max_score_word_question = words #The word with the maximum td-idf score is stoked here
    president_name = list_of_files("./cleaned", "txt")

    tf_idf_matrix = transpose_matrix(td_idf_matrix("./cleaned"))
    question_tf_idf_vector = td_idf_matrix_question("./cleaned", "question")
    the_doc = find_most_relevant_document(tf_idf_matrix, question_tf_idf_vector, president_name)

    response = ''
   
    with open(os.path.join("./cleaned", the_doc), "r", encoding='utf-8') as f:
        content = f.read().split()
        for i in range(len(content)-1):
            if content[i] == max_score_word_question:
                j = i
                while j > 0 and not content[j].endswith("."):
                    response[-1] += content[j]
                    j -= 1

                j = i+1
                while j < len(content) and not content[j].endswith("."):
                    response += content[j]
                    j += 1

        return response.strip().capitalize()+'.'

def generate_formatted_response(question, response):
    """Format the response based on the form of the question"""
    question_starters = {
        "Comment": "Après analyse, ",
        "Pourquoi": "Car, ",
        "Peux-tu": "Oui, bien sûr!"
    }

    for starter, model_response in question_starters.items():
        if question.startswith(starter):
            return model_response + response

    return response
